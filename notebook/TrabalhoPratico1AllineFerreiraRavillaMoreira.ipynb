{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook - Spaceship Titanic\n",
        "###Trabalho pr√°tico 01\n",
        "####Alunas: Alline Ferreira e R√°villa Moreira"
      ],
      "metadata": {
        "id": "KpYIeFVgiCOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import optuna\n"
      ],
      "metadata": {
        "id": "zJlB3q0GhnoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv("/kaggle/input/spaceship-titanic/train.csv").drop(['ID_code'],axis=1)",
        "test=pd.read_csv("/kaggle/input/spaceship-titanic/test.csv").drop(['ID_code'],axis=1)",
        "sample_sub = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')"
      ],
      "metadata": {
        "id": "6Gy3dZkQhpvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar colunas num√©ricas e categ√≥ricas\n",
        "num_cols = train.select_dtypes(include=np.number).columns.drop(\"Transported\")\n",
        "cat_cols = train.select_dtypes(exclude=np.number).columns.drop(\"PassengerId\")\n",
        "\n",
        "# Copiar dataset para manipula√ß√£o\n",
        "df = train.copy()\n",
        "\n",
        "# Imputa√ß√£o de valores ausentes\n",
        "for col in num_cols:\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "for col in cat_cols:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "# Codifica√ß√£o de vari√°veis categ√≥ricas\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Separar features e target\n",
        "X = df.drop([\"Transported\", \"PassengerId\"], axis=1)\n",
        "y = df[\"Transported\"].astype(int)\n",
        "\n",
        "# Escalonamento\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split treino/teste\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "HpvITWihhrWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "baseline_acc = cross_val_score(dummy, X_scaled, y, cv=cv, scoring=\"accuracy\").mean()\n",
        "print(\"Baseline Accuracy:\", baseline_acc)\n"
      ],
      "metadata": {
        "id": "4kRxI0GYhtHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric=\"logloss\"),\n",
        "    \"KNN\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    acc = cross_val_score(model, X_scaled, y, cv=cv, scoring=\"accuracy\").mean()\n",
        "    results[name] = acc\n",
        "\n",
        "print(pd.DataFrame(results.items(), columns=[\"Modelo\", \"Accuracy\"]))\n"
      ],
      "metadata": {
        "id": "wiZiyZTwhusj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"rf\", RandomForestClassifier(random_state=42)),\n",
        "        (\"xgb\", XGBClassifier(random_state=42, eval_metric=\"logloss\")),\n",
        "        (\"knn\", KNeighborsClassifier())\n",
        "    ],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "\n",
        "ensemble_acc = cross_val_score(voting, X_scaled, y, cv=cv, scoring=\"accuracy\").mean()\n",
        "print(\"VotingClassifier Accuracy:\", ensemble_acc)\n"
      ],
      "metadata": {
        "id": "PGXEg7B8hwFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=42\n",
        "    )\n",
        "    return cross_val_score(rf, X_scaled, y, cv=cv, scoring=\"accuracy\").mean()\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Melhores par√¢metros:\", study.best_params)\n",
        "print(\"Melhor accuracy:\", study.best_value)\n"
      ],
      "metadata": {
        "id": "h3iTcA_whxYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test.copy()\n",
        "\n",
        "# Imputa√ß√£o de valores ausentes (mesma estrat√©gia do treino)\n",
        "for col in num_cols:\n",
        "    test_df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "for col in cat_cols:\n",
        "    test_df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "# Codifica√ß√£o (mesmo LabelEncoder do treino)\n",
        "for col in cat_cols:\n",
        "    test_df[col] = le.fit_transform(test_df[col])\n",
        "\n",
        "# Escalonamento (mesmo StandardScaler do treino)\n",
        "test_scaled = scaler.transform(test_df.drop(\"PassengerId\", axis=1))\n",
        "\n",
        "best_rf = RandomForestClassifier(\n",
        "    n_estimators=study.best_params[\"n_estimators\"],\n",
        "    max_depth=study.best_params[\"max_depth\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_rf.fit(X_scaled, y)\n",
        "predictions = best_rf.predict(test_scaled)\n",
        "predictions_bool = predictions.astype(bool)\n",
        "\n",
        "# =========================\n",
        "# üîπ Criar submission.csv\n",
        "# =========================\n",
        "submission = pd.DataFrame({\n",
        "    \"PassengerId\": test[\"PassengerId\"],\n",
        "    \"Transported\": predictions_bool\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"‚úÖ Arquivo submission.csv gerado com sucesso!\")\n",
        "submission.head()\n"
      ],
      "metadata": {
        "id": "DFi28VpdhyrH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
