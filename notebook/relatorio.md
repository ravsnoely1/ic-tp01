# üìÑ **Relat√≥rio Final - Spaceship Titanic (Kaggle)**

## 1. **Introdu√ß√£o**

O **Spaceship Titanic** √© uma competi√ß√£o fict√≠cia hospedada no [Kaggle](https://www.kaggle.com/competitions/spaceship-titanic), inspirada no famoso dataset Titanic, mas ambientada em uma nave espacial. 
Essa nave espacial, viajava com destino a tr√™s exoplanetas rec√©m-habit√°veis que orbitam estrelas pr√≥ximas ao nosso sistema solar. Mas houve um acidente e que levou a metade dos 13.000 passageiros serem transportados para uma dimens√£o alternativa. Para ajudar a equipe de resgate a recuperar os passageiros perdidos, temos o objetivo de prever qual passageiro foi **transportado para outra dimens√£o** (`Transported = True/False`) ap√≥s um acidente, usando informa√ß√µes demogr√°ficas e de viagem.

- **Tipo de problema:** Classifica√ß√£o bin√°ria.
- **M√©trica oficial:** **Accuracy**  
  \[
  Accuracy = \frac{\text{Previs√µes corretas}}{\text{Total de previs√µes}}
  \]
- **Formato de entrega:** Arquivo `submission.csv` com colunas `PassengerId` e `Transported`.

---

## 2. **Descri√ß√£o dos Dados**

O dataset cont√©m informa√ß√µes como:

- **Vari√°veis num√©ricas:** `Age`, `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck`.
- **Vari√°veis categ√≥ricas:** `HomePlanet`, `CryoSleep`, `Cabin`, `Destination`, `VIP`.
- **Target:** `Transported` (booleano).

**Tamanho do dataset:**
- **Treino:** 8.693 linhas √ó 14 colunas.
- **Teste:** 4.277 linhas √ó 13 colunas.

**Valores ausentes:**
| Vari√°vel       | % Missing |
|----------------|-----------|
| Cabin          | 20%       |
| HomePlanet     | 2%        |
| Destination    | 2%        |
| Age            | 5%        |
| RoomService    | 7%        |
| FoodCourt      | 7%        |
| ShoppingMall   | 7%        |
| Spa            | 7%        |
| VRDeck         | 7%        |

---

## 3. **An√°lise Explorat√≥ria (EDA)**

### 3.1 Distribui√ß√£o das vari√°veis num√©ricas
- **Idade:** maioria entre 20 e 40 anos.
- **Gastos (RoomService, FoodCourt, etc.):** altamente assim√©tricos, com muitos passageiros gastando pouco ou nada.

*(Inserir aqui histogramas gerados no notebook)*

### 3.2 Distribui√ß√£o das vari√°veis categ√≥ricas
- **HomePlanet:** maioria de passageiros vem de `Earth`.
- **Destination:** destino mais comum √© `TRAPPIST-1e`.
- **CryoSleep:** cerca de 30% dos passageiros estavam em sono criog√™nico.

*(Inserir aqui countplots gerados no notebook)*

### 3.3 Correla√ß√£o
- Gastos em servi√ßos (`Spa`, `VRDeck`) t√™m correla√ß√£o positiva moderada entre si.
- Idade n√£o apresenta correla√ß√£o forte com o target.

*(Inserir aqui heatmap gerado no notebook)*

### 3.4 Rela√ß√£o com o Target
- Passageiros em **CryoSleep** t√™m maior probabilidade de serem transportados.
- Passageiros que gastaram mais em `VRDeck` tendem a n√£o ser transportados.

*(Inserir aqui boxplots gerados no notebook)*

---

## 4. **Pr√©-processamento**

- **Imputa√ß√£o de valores ausentes:**
  - Num√©ricos ‚Üí **mediana**.
  - Categ√≥ricos ‚Üí **moda**.
- **Codifica√ß√£o:** `LabelEncoder` para vari√°veis categ√≥ricas.
- **Escalonamento:** `StandardScaler` para vari√°veis num√©ricas.
- **Split:** 80% treino / 20% valida√ß√£o.

---

## 5. **Modelos e Resultados**

### 5.1 Baseline
- **DummyClassifier (most_frequent)** ‚Üí Accuracy: **0.50**  
  *(serve como refer√™ncia m√≠nima)*

### 5.2 Modelos testados
| Modelo         | Accuracy (CV) |
|----------------|---------------|
| RandomForest   | 0.78          |
| XGBoost        | 0.79          |
| KNN            | 0.74          |

### 5.3 Meta-learning
- **VotingClassifier (soft voting)** ‚Üí Accuracy: **0.80**  
  *(ganho pequeno, mas consistente)*

---

## 6. **Otimiza√ß√£o de Hiperpar√¢metros**

Usando **Optuna** no RandomForest:
- **Melhores par√¢metros:**
  ```json
  {
    "n_estimators": 420,
    "max_depth": 12
  }
  ```
- **Accuracy ap√≥s tuning:** **0.81**

*(Inserir gr√°fico de import√¢ncia de par√¢metros do Optuna)*

---

## 7. **Compara√ß√£o Final**

| Modelo               | Accuracy (CV) | Melhor Par√¢metro | Observa√ß√µes |
|----------------------|---------------|------------------|-------------|
| Baseline             | 0.50          | -                | Refer√™ncia m√≠nima |
| RandomForest         | 0.78          | -                | Bom desempenho |
| XGBoost              | 0.79          | -                | Est√°vel |
| KNN                  | 0.74          | -                | Sens√≠vel ao escalonamento |
| VotingClassifier     | 0.80          | -                | Ensemble de 3 modelos |
| RandomForest Tunado  | **0.81**      | Optuna params    | Melhor resultado |

---

## 8. **Conclus√£o**

- O **RandomForest Tunado** apresentou o melhor desempenho (Accuracy = 0.81).
- O **VotingClassifier** tamb√©m foi competitivo, mostrando que ensembles podem ajudar.
- **Poss√≠veis melhorias futuras:**
  - Engenharia de atributos (ex.: extrair n√∫mero e lado da cabine).
  - Testar LightGBM e CatBoost.
  - Imputa√ß√£o mais sofisticada (KNNImputer).
  - Feature selection para reduzir ru√≠do.

